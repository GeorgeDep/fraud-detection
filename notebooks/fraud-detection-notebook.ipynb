{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "Zyd_Opt2RQSG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGudin2VNXSN"
      },
      "outputs": [],
      "source": [
        "# Install only the packages not in Colab by default\n",
        "!pip install -q grad-cam kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core ML libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import transforms\n",
        "import timm\n",
        "\n",
        "# Grad-CAM for interpretability\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "# Data processing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# Visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Utility libraries\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Hugging Face libraries\n",
        "import transformers\n",
        "from transformers import AutoImageProcessor\n",
        "from datasets import Dataset as HFDataset\n",
        "\n",
        "import zipfile\n",
        "import requests\n",
        "\n",
        "from google.colab import drive, files"
      ],
      "metadata": {
        "id": "8vHn_GTKNqQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# System Check"
      ],
      "metadata": {
        "id": "Xf_VU-DlRVHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick system check\n",
        "print(f\"PyTorch: {torch.__version__} | CUDA: {torch.cuda.is_available()}\")\n",
        "print(f\"TIMM: {timm.__version__} | Transformers: {transformers.__version__}\")\n",
        "\n",
        "# Create project structure\n",
        "os.makedirs('data/authentic', exist_ok=True)\n",
        "os.makedirs('data/tampered', exist_ok=True)\n",
        "\n",
        "free_gb = shutil.disk_usage(\"/\")[2] // (2**30)\n",
        "print(f\"Available space: {free_gb} GB\")"
      ],
      "metadata": {
        "id": "vCbqrTtYNuuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pipeline"
      ],
      "metadata": {
        "id": "og1acaQKRbc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_drive():\n",
        "    \"\"\"Mount Drive and create project structure\"\"\"\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Create project directory in Drive\n",
        "    project_dir = '/content/drive/MyDrive/fraud_detection'\n",
        "    os.makedirs(project_dir, exist_ok=True)\n",
        "    os.makedirs(f'{project_dir}/models', exist_ok=True)\n",
        "    os.makedirs(f'{project_dir}/outputs', exist_ok=True)\n",
        "    os.makedirs(f'{project_dir}/data_splits', exist_ok=True)\n",
        "\n",
        "    print(f\"Project directory created: {project_dir}\")\n",
        "    return project_dir\n",
        "\n",
        "def check_colab_resources():\n",
        "    \"\"\"Verify Colab environment setup\"\"\"\n",
        "    print(\"=== Colab Environment Check ===\")\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        print(f\"GPU: {gpu_name}\")\n",
        "        print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "    # Check disk space\n",
        "    total, used, free = shutil.disk_usage('/')\n",
        "    print(f\"Disk space: {free / 1e9:.1f} GB free\")\n",
        "\n",
        "    return torch.cuda.is_available()\n",
        "\n",
        "def setup_kaggle_colab():\n",
        "    \"\"\"Setup Kaggle API in Colab with file upload\"\"\"\n",
        "    print(\"Setting up Kaggle API...\")\n",
        "\n",
        "    # Install Kaggle\n",
        "    os.system(\"pip install kaggle -q\")\n",
        "\n",
        "    # Upload kaggle.json\n",
        "    print(\"Please upload your kaggle.json file:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if 'kaggle.json' in uploaded:\n",
        "        # Setup credentials\n",
        "        os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "        shutil.move('kaggle.json', '/root/.kaggle/kaggle.json')\n",
        "        os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
        "        print(\"Kaggle credentials configured successfully\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"kaggle.json not uploaded\")\n",
        "        return False\n",
        "\n",
        "def download_casia_optimized():\n",
        "    \"\"\"Download CASIA dataset optimized for Colab performance\"\"\"\n",
        "\n",
        "    # Create temp directories for fast processing\n",
        "    os.makedirs('/content/data/authentic', exist_ok=True)\n",
        "    os.makedirs('/content/data/tampered', exist_ok=True)\n",
        "\n",
        "    print(\"Downloading CASIA dataset to temp storage...\")\n",
        "\n",
        "    # Download to temp storage\n",
        "    download_cmd = \"kaggle datasets download -d divg07/casia-20-image-tampering-detection-dataset -p /content/\"\n",
        "    result = os.system(download_cmd)\n",
        "\n",
        "    if result != 0:\n",
        "        print(\"Download failed\")\n",
        "        return False\n",
        "\n",
        "    # Extract dataset\n",
        "    print(\"Extracting dataset...\")\n",
        "    zip_files = list(Path('/content/').glob('*.zip'))\n",
        "    if not zip_files:\n",
        "        print(\"No zip file found\")\n",
        "        return False\n",
        "\n",
        "    with zipfile.ZipFile(zip_files[0], 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/raw')\n",
        "\n",
        "    # Find and organize\n",
        "    print(\"Organizing dataset...\")\n",
        "    raw_dir = Path('/content/raw')\n",
        "\n",
        "    # Search for Au and Tp folders\n",
        "    au_folder = None\n",
        "    tp_folder = None\n",
        "\n",
        "    for item in raw_dir.rglob('*'):\n",
        "        if item.is_dir() and item.name == 'Au':\n",
        "            au_folder = item\n",
        "        elif item.is_dir() and item.name == 'Tp':\n",
        "            tp_folder = item\n",
        "\n",
        "    if not au_folder or not tp_folder:\n",
        "        print(\"Could not find Au/Tp folders\")\n",
        "        return False\n",
        "\n",
        "    # Copy to organized structure\n",
        "    authentic_count = 0\n",
        "    tampered_count = 0\n",
        "\n",
        "    print(\"Copying authentic images...\")\n",
        "    for img in au_folder.glob('*.jpg'):\n",
        "        shutil.copy(img, '/content/data/authentic/')\n",
        "        authentic_count += 1\n",
        "\n",
        "    print(\"Copying tampered images...\")\n",
        "    for img in tp_folder.glob('*.jpg'):\n",
        "        shutil.copy(img, '/content/data/tampered/')\n",
        "        tampered_count += 1\n",
        "\n",
        "    # Cleanup temp files\n",
        "    os.remove(zip_files[0])\n",
        "    shutil.rmtree('/content/raw')\n",
        "\n",
        "    print(f\"Dataset ready: {authentic_count} authentic, {tampered_count} tampered\")\n",
        "    return True\n",
        "\n",
        "def create_train_splits(project_dir):\n",
        "    \"\"\"Create train/val/test splits and save to Drive\"\"\"\n",
        "    print(\"Creating data splits...\")\n",
        "\n",
        "    # Get file lists\n",
        "    authentic_files = list(Path('/content/data/authentic').glob('*.jpg'))\n",
        "    tampered_files = list(Path('/content/data/tampered').glob('*.jpg'))\n",
        "\n",
        "    # Create labels\n",
        "    data = []\n",
        "    for f in authentic_files:\n",
        "        data.append({'file_path': str(f), 'label': 0, 'class': 'authentic'})\n",
        "    for f in tampered_files:\n",
        "        data.append({'file_path': str(f), 'label': 1, 'class': 'tampered'})\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Split data\n",
        "    train_df, temp_df = train_test_split(df, test_size=0.4, stratify=df['label'], random_state=42)\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
        "\n",
        "    # Save splits to Drive\n",
        "    splits_dir = f'{project_dir}/data_splits'\n",
        "    train_df.to_csv(f'{splits_dir}/train_split.csv', index=False)\n",
        "    val_df.to_csv(f'{splits_dir}/val_split.csv', index=False)\n",
        "    test_df.to_csv(f'{splits_dir}/test_split.csv', index=False)\n",
        "\n",
        "    print(f\"Data splits created:\")\n",
        "    print(f\"  Train: {len(train_df)} images\")\n",
        "    print(f\"  Validation: {len(val_df)} images\")\n",
        "    print(f\"  Test: {len(test_df)} images\")\n",
        "    print(f\"Splits saved to Google Drive\")\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "def complete_colab_setup():\n",
        "    \"\"\"Run complete setup for Colab environment\"\"\"\n",
        "    print(\"Starting Colab setup for fraud detection project...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Step 1: Check resources\n",
        "    has_gpu = check_colab_resources()\n",
        "    if not has_gpu:\n",
        "        print(\"WARNING: No GPU detected. Enable GPU in Runtime -> Change runtime type\")\n",
        "        return False\n",
        "\n",
        "    # Step 2: Setup Drive\n",
        "    project_dir = setup_drive()\n",
        "\n",
        "    # Step 3: Setup Kaggle\n",
        "    if not setup_kaggle_colab():\n",
        "        return False\n",
        "\n",
        "    # Step 4: Download dataset\n",
        "    if not download_casia_optimized():\n",
        "        return False\n",
        "\n",
        "    # Step 5: Create splits\n",
        "    train_df, val_df, test_df = create_train_splits(project_dir)\n",
        "\n",
        "    print(\"\\nSetup complete! Ready for model training.\")\n",
        "    print(f\"Dataset: {len(train_df) + len(val_df) + len(test_df)} total images\")\n",
        "    print(f\"Working directory: /content/data/\")\n",
        "    print(f\"Results will be saved to: {project_dir}\")\n",
        "\n",
        "    return True\n",
        "\n",
        "def verify_setup():\n",
        "    \"\"\"Verify everything is ready\"\"\"\n",
        "    auth_count = len(list(Path('/content/data/authentic').glob('*.jpg')))\n",
        "    tamp_count = len(list(Path('/content/data/tampered').glob('*.jpg')))\n",
        "\n",
        "    print(f\"Dataset verification:\")\n",
        "    print(f\"  Authentic: {auth_count}\")\n",
        "    print(f\"  Tampered: {tamp_count}\")\n",
        "    print(f\"  GPU available: {torch.cuda.is_available()}\")\n",
        "\n",
        "    # Check if splits exist in Drive\n",
        "    project_dir = '/content/drive/MyDrive/fraud_detection'\n",
        "    splits_exist = all([\n",
        "        Path(f'{project_dir}/data_splits/train_split.csv').exists(),\n",
        "        Path(f'{project_dir}/data_splits/val_split.csv').exists(),\n",
        "        Path(f'{project_dir}/data_splits/test_split.csv').exists()\n",
        "    ])\n",
        "    print(f\"  Data splits ready: {splits_exist}\")\n",
        "\n",
        "    return auth_count > 0 and tamp_count > 0 and torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "1ND83biLPRoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "bBcS3JP_Rk66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run complete Colab setup\n",
        "if complete_colab_setup():\n",
        "    verify_setup()\n",
        "    print(\"Ready to start training!\")\n",
        "else:\n",
        "    print(\"Setup failed - check the steps above\")"
      ],
      "metadata": {
        "id": "fFGohZyKPcEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Pipeline"
      ],
      "metadata": {
        "id": "3YbFvvPgRsJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EfficientNet Training Pipeline for Fraud Detection\n",
        "\n",
        "class FraudDataset(Dataset):\n",
        "    \"\"\"Custom dataset for fraud detection images\"\"\"\n",
        "\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.data = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        image_path = row['file_path']\n",
        "        label = row['label']\n",
        "\n",
        "        # Load image\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "def create_transforms():\n",
        "    \"\"\"Create training and validation transforms\"\"\"\n",
        "\n",
        "    # Training transforms with augmentation\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                           std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Validation/test transforms (no augmentation)\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                           std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    return train_transform, val_transform\n",
        "\n",
        "def create_model(num_classes=2):\n",
        "    \"\"\"Create EfficientNet-B0 model for fraud detection\"\"\"\n",
        "\n",
        "    # Load pre-trained EfficientNet-B0\n",
        "    model = timm.create_model('efficientnet_b0.ra_in1k',\n",
        "                             pretrained=True,\n",
        "                             num_classes=num_classes)\n",
        "\n",
        "    print(f\"Model created: EfficientNet-B0\")\n",
        "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_data_loaders(batch_size=32):\n",
        "    \"\"\"Create data loaders for training, validation, and testing\"\"\"\n",
        "\n",
        "    # Load data splits\n",
        "    project_dir = '/content/drive/MyDrive/fraud_detection'\n",
        "    train_df = pd.read_csv(f'{project_dir}/data_splits/train_split.csv')\n",
        "    val_df = pd.read_csv(f'{project_dir}/data_splits/val_split.csv')\n",
        "    test_df = pd.read_csv(f'{project_dir}/data_splits/test_split.csv')\n",
        "\n",
        "    # Create transforms\n",
        "    train_transform, val_transform = create_transforms()\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = FraudDataset(train_df, transform=train_transform)\n",
        "    val_dataset = FraudDataset(val_df, transform=val_transform)\n",
        "    test_dataset = FraudDataset(test_df, transform=val_transform)\n",
        "\n",
        "    # Calculate class weights for imbalanced dataset\n",
        "    class_counts = train_df['label'].value_counts().sort_index()\n",
        "    total_samples = len(train_df)\n",
        "    class_weights = [total_samples / (2 * count) for count in class_counts]\n",
        "    print(f\"Class distribution: {class_counts.values}\")\n",
        "    print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                             shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
        "                           shuffle=False, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
        "                            shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    print(f\"Data loaders created:\")\n",
        "    print(f\"  Train batches: {len(train_loader)}\")\n",
        "    print(f\"  Val batches: {len(val_loader)}\")\n",
        "    print(f\"  Test batches: {len(test_loader)}\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader, class_weights\n",
        "\n",
        "def train_model(model, train_loader, val_loader, class_weights, num_epochs=15):\n",
        "    \"\"\"Train the fraud detection model\"\"\"\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Loss function with class weights for imbalanced data\n",
        "    weights = torch.FloatTensor(class_weights).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    # Optimizer with learning rate scheduling\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                    factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "    # Training history\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'val_loss': [],\n",
        "        'val_acc': []\n",
        "    }\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    best_model_state = None\n",
        "\n",
        "    print(f\"Starting training on {device}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Print progress every 50 batches\n",
        "            if batch_idx % 50 == 0:\n",
        "                print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, '\n",
        "                      f'Loss: {loss.item():.4f}')\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Calculate metrics\n",
        "        train_loss_avg = train_loss / len(train_loader)\n",
        "        train_acc = 100 * train_correct / train_total\n",
        "        val_loss_avg = val_loss / len(val_loader)\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "\n",
        "        # Update history\n",
        "        history['train_loss'].append(train_loss_avg)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss_avg)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        scheduler.step(val_loss_avg)\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_state = model.state_dict().copy()\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'  Train Loss: {train_loss_avg:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "        print(f'  Val Loss: {val_loss_avg:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "        print(f'  Best Val Acc: {best_val_acc:.2f}%')\n",
        "        print('-' * 30)\n",
        "\n",
        "    # Load best model (this ensures we're using the best performing epoch)\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "    # Save model and training history with timestamp\n",
        "    project_dir = '/content/drive/MyDrive/fraud_detection'\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # Save model state dict with metadata\n",
        "    torch.save({\n",
        "        'model_state_dict': best_model_state,\n",
        "        'model_config': 'efficientnet_b0.ra_in1k',\n",
        "        'num_classes': 2,\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'class_weights': class_weights,\n",
        "        'timestamp': timestamp\n",
        "    }, f'{project_dir}/models/fraud_detection_model_{timestamp}.pth')\n",
        "\n",
        "    # Save complete model for SageMaker deployment (this is the key addition you were missing)\n",
        "    torch.save(model, f'{project_dir}/models/fraud_detection_complete_{timestamp}.pth')\n",
        "\n",
        "    # Save training history\n",
        "    with open(f'{project_dir}/outputs/training_history_{timestamp}.json', 'w') as f:\n",
        "        json.dump(history, f, indent=2)\n",
        "\n",
        "    print(f\"Training completed!\")\n",
        "    print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "    print(f\"Model saved to Google Drive\")\n",
        "    print(f\"Complete model (SageMaker ready): fraud_detection_complete_{timestamp}.pth\")\n",
        "\n",
        "    return model, history\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training and validation metrics\"\"\"\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # Plot loss\n",
        "    ax1.plot(history['train_loss'], label='Train Loss')\n",
        "    ax1.plot(history['val_loss'], label='Val Loss')\n",
        "    ax1.set_title('Training and Validation Loss')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Plot accuracy\n",
        "    ax2.plot(history['train_acc'], label='Train Accuracy')\n",
        "    ax2.plot(history['val_acc'], label='Val Accuracy')\n",
        "    ax2.set_title('Training and Validation Accuracy')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy (%)')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save plot with timestamp\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    plt.savefig(f'/content/drive/MyDrive/fraud_detection/outputs/training_curves_{timestamp}.png',\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# Setup training pipeline\n",
        "def setup_training():\n",
        "    \"\"\"Initialize everything for training\"\"\"\n",
        "    print(\"Setting up training pipeline...\")\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader, val_loader, test_loader, class_weights = create_data_loaders(batch_size=32)\n",
        "\n",
        "    # Create model\n",
        "    model = create_model(num_classes=2)\n",
        "\n",
        "    return model, train_loader, val_loader, test_loader, class_weights"
      ],
      "metadata": {
        "id": "5CMQ7ayNQ3Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "8BiNQJ8ERv6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start the training\n",
        "model, train_loader, val_loader, test_loader, class_weights = setup_training()\n",
        "model, history = train_model(model, train_loader, val_loader, class_weights, num_epochs=15)\n",
        "plot_training_history(history)"
      ],
      "metadata": {
        "id": "Uw43w8RdQ7eB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Pipeline"
      ],
      "metadata": {
        "id": "QjzQbDOBVkO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_best_model(timestamp=None):\n",
        "    \"\"\"Load the best trained model for testing\"\"\"\n",
        "    project_dir = '/content/drive/MyDrive/fraud_detection'\n",
        "\n",
        "    if timestamp is None:\n",
        "        # Find most recent model if no timestamp provided\n",
        "        model_files = list(Path(f'{project_dir}/models').glob('fraud_detection_complete_*.pth'))\n",
        "        if not model_files:\n",
        "            print(\"No trained models found\")\n",
        "            return None\n",
        "        # Get most recent model\n",
        "        model_path = max(model_files, key=os.path.getctime)\n",
        "        timestamp = model_path.stem.split('_')[-2] + '_' + model_path.stem.split('_')[-1]\n",
        "    else:\n",
        "        model_path = f'{project_dir}/models/fraud_detection_complete_{timestamp}.pth'\n",
        "\n",
        "    print(f\"Loading model: {model_path}\")\n",
        "    model = torch.load(model_path, map_location='cpu', weights_only=False)\n",
        "\n",
        "    # Move to GPU if available\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"Model loaded successfully on {device}\")\n",
        "    return model, timestamp\n",
        "\n",
        "def evaluate_on_test_set(model, test_loader):\n",
        "    \"\"\"Comprehensive evaluation on test set\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_probabilities = []\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    print(\"Evaluating model on test set...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Get model outputs\n",
        "            outputs = model(images)\n",
        "            probabilities = torch.softmax(outputs, dim=1)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # Store results\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probabilities.extend(probabilities.cpu().numpy())\n",
        "\n",
        "            # Calculate running accuracy\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "            if batch_idx % 20 == 0:\n",
        "                print(f'Test batch {batch_idx}/{len(test_loader)} processed')\n",
        "\n",
        "    # Calculate final metrics\n",
        "    test_accuracy = correct_predictions / total_samples\n",
        "\n",
        "    print(f\"\\nTest Set Results:\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "    print(f\"Total samples: {total_samples}\")\n",
        "    print(f\"Correct predictions: {correct_predictions}\")\n",
        "\n",
        "    return all_predictions, all_labels, all_probabilities, test_accuracy\n",
        "\n",
        "def generate_detailed_metrics(predictions, labels, probabilities, timestamp):\n",
        "    \"\"\"Generate comprehensive evaluation metrics and save results\"\"\"\n",
        "    from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    # Classification report\n",
        "    class_names = ['Authentic', 'Tampered']\n",
        "    report = classification_report(labels, predictions, target_names=class_names, output_dict=True)\n",
        "\n",
        "    print(\"\\nDetailed Classification Report:\")\n",
        "    print(classification_report(labels, predictions, target_names=class_names))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(labels, predictions)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix - Fraud Detection Model')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "\n",
        "    # Save confusion matrix\n",
        "    project_dir = '/content/drive/MyDrive/fraud_detection'\n",
        "    plt.savefig(f'{project_dir}/outputs/confusion_matrix_{timestamp}.png',\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # ROC curve and AUC\n",
        "    probabilities_array = np.array(probabilities)\n",
        "    tampered_probs = probabilities_array[:, 1]  # Probabilities for tampered class\n",
        "\n",
        "    auc_score = roc_auc_score(labels, tampered_probs)\n",
        "    fpr, tpr, _ = roc_curve(labels, tampered_probs)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {auc_score:.3f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve - Fraud Detection Model')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Save ROC curve\n",
        "    plt.savefig(f'{project_dir}/outputs/roc_curve_{timestamp}.png',\n",
        "                dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Save detailed results\n",
        "    results = {\n",
        "        'test_accuracy': float(np.mean(np.array(predictions) == np.array(labels))),\n",
        "        'auc_score': float(auc_score),\n",
        "        'classification_report': report,\n",
        "        'confusion_matrix': cm.tolist(),\n",
        "        'timestamp': timestamp,\n",
        "        'total_samples': len(labels)\n",
        "    }\n",
        "\n",
        "    with open(f'{project_dir}/outputs/test_evaluation_{timestamp}.json', 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    print(f\"\\nAUC Score: {auc_score:.4f}\")\n",
        "    print(f\"Results saved to: {project_dir}/outputs/\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def analyze_prediction_confidence(predictions, labels, probabilities):\n",
        "    \"\"\"Analyze model confidence in predictions\"\"\"\n",
        "    probabilities_array = np.array(probabilities)\n",
        "    max_probs = np.max(probabilities_array, axis=1)\n",
        "\n",
        "    # Separate correct and incorrect predictions\n",
        "    correct_mask = np.array(predictions) == np.array(labels)\n",
        "    correct_confidence = max_probs[correct_mask]\n",
        "    incorrect_confidence = max_probs[~correct_mask]\n",
        "\n",
        "    print(f\"\\nPrediction Confidence Analysis:\")\n",
        "    print(f\"Correct predictions - Mean confidence: {np.mean(correct_confidence):.4f}\")\n",
        "    print(f\"Incorrect predictions - Mean confidence: {np.mean(incorrect_confidence):.4f}\")\n",
        "    print(f\"High confidence correct (>0.9): {np.sum(correct_confidence > 0.9)} / {len(correct_confidence)}\")\n",
        "    print(f\"High confidence incorrect (>0.9): {np.sum(incorrect_confidence > 0.9)} / {len(incorrect_confidence)}\")\n",
        "\n",
        "    # Plot confidence distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(correct_confidence, bins=30, alpha=0.7, label='Correct Predictions', color='green')\n",
        "    plt.hist(incorrect_confidence, bins=30, alpha=0.7, label='Incorrect Predictions', color='red')\n",
        "    plt.xlabel('Prediction Confidence')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of Prediction Confidence')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def test_individual_samples(model, test_loader, num_samples=8):\n",
        "    \"\"\"Test model on individual samples and show predictions\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.eval()\n",
        "\n",
        "    # Get a batch of test data\n",
        "    images, labels = next(iter(test_loader))\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # Plot sample predictions\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    class_names = ['Authentic', 'Tampered']\n",
        "\n",
        "    for i in range(min(num_samples, len(images))):\n",
        "        # Denormalize image for display\n",
        "        img = images[i].cpu()\n",
        "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "        img = img * std + mean\n",
        "        img = torch.clamp(img, 0, 1)\n",
        "\n",
        "        # Convert to numpy and transpose\n",
        "        img_np = img.permute(1, 2, 0).numpy()\n",
        "\n",
        "        axes[i].imshow(img_np)\n",
        "\n",
        "        true_label = class_names[labels[i].item()]\n",
        "        pred_label = class_names[predicted[i].item()]\n",
        "        confidence = probabilities[i].max().item()\n",
        "\n",
        "        color = 'green' if predicted[i] == labels[i] else 'red'\n",
        "        axes[i].set_title(f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.3f}',\n",
        "                         color=color, fontsize=10)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle('Sample Predictions from Test Set', fontsize=16)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gwW5bS-9VmcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Results"
      ],
      "metadata": {
        "id": "kPDca7MyXfeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model (using your timestamp)\n",
        "model, timestamp = load_best_model('20250603_145722')\n",
        "\n",
        "# Create test data loader if not already available\n",
        "if 'test_loader' not in locals():\n",
        "    print(\"Creating test data loader...\")\n",
        "    _, _, test_loader, _ = create_data_loaders(batch_size=32)\n",
        "\n",
        "# Run comprehensive evaluation\n",
        "print(\"Starting comprehensive model evaluation...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "predictions, labels, probabilities, test_accuracy = evaluate_on_test_set(model, test_loader)"
      ],
      "metadata": {
        "id": "CS6sGx5lV5jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis & Visualisation"
      ],
      "metadata": {
        "id": "7LGYYTcrgqJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate detailed metrics and visualizations\n",
        "results = generate_detailed_metrics(predictions, labels, probabilities, timestamp)\n",
        "\n",
        "# Analyze prediction confidence\n",
        "analyze_prediction_confidence(predictions, labels, probabilities)\n",
        "\n",
        "# Test individual samples\n",
        "test_individual_samples(model, test_loader, num_samples=8)\n",
        "\n",
        "print(\"\\nModel testing completed!\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n",
        "print(f\"All results saved with timestamp: {timestamp}\")"
      ],
      "metadata": {
        "id": "_-jxoxXCWAMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_performance_summary(results):\n",
        "    \"\"\"Print comprehensive performance summary\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FRAUD DETECTION MODEL - PERFORMANCE SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"Model Timestamp: {results['timestamp']}\")\n",
        "    print(f\"Test Accuracy: {results['test_accuracy']*100:.2f}%\")\n",
        "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
        "    print(f\"Total Test Samples: {results['total_samples']}\")\n",
        "\n",
        "    # Extract metrics from classification report\n",
        "    report = results['classification_report']\n",
        "\n",
        "    print(f\"\\nPer-Class Performance:\")\n",
        "    print(f\"Authentic Images:\")\n",
        "    print(f\"  Precision: {report['Authentic']['precision']:.4f}\")\n",
        "    print(f\"  Recall: {report['Authentic']['recall']:.4f}\")\n",
        "    print(f\"  F1-Score: {report['Authentic']['f1-score']:.4f}\")\n",
        "\n",
        "    print(f\"Tampered Images:\")\n",
        "    print(f\"  Precision: {report['Tampered']['precision']:.4f}\")\n",
        "    print(f\"  Recall: {report['Tampered']['recall']:.4f}\")\n",
        "    print(f\"  F1-Score: {report['Tampered']['f1-score']:.4f}\")\n",
        "\n",
        "    print(f\"\\nOverall Metrics:\")\n",
        "    print(f\"  Macro Avg F1: {report['macro avg']['f1-score']:.4f}\")\n",
        "    print(f\"  Weighted Avg F1: {report['weighted avg']['f1-score']:.4f}\")\n",
        "\n",
        "    # Confusion matrix analysis\n",
        "    cm = np.array(results['confusion_matrix'])\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(f\"\\nConfusion Matrix Breakdown:\")\n",
        "    print(f\"  True Negatives (Authentic correctly identified): {tn}\")\n",
        "    print(f\"  False Positives (Authentic misclassified as Tampered): {fp}\")\n",
        "    print(f\"  False Negatives (Tampered misclassified as Authentic): {fn}\")\n",
        "    print(f\"  True Positives (Tampered correctly identified): {tp}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Print comprehensive summary\n",
        "print_performance_summary(results)"
      ],
      "metadata": {
        "id": "ZWMRsKXiWDt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grad-CAM Implementation"
      ],
      "metadata": {
        "id": "35xtXoTddDk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "class FraudDetectionExplainer:\n",
        "    \"\"\"\n",
        "    Grad-CAM explainer for fraud detection model\n",
        "    Analyzes what features the model focuses on for tampering detection\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, target_layers=None):\n",
        "        \"\"\"\n",
        "        Initialize explainer with trained model\n",
        "\n",
        "        Args:\n",
        "            model: Trained PyTorch model\n",
        "            target_layers: Target layers for Grad-CAM (auto-detected if None)\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.device = next(model.parameters()).device\n",
        "\n",
        "        # Auto-detect target layer for EfficientNet if not specified\n",
        "        if target_layers is None:\n",
        "            target_layers = self._find_target_layers()\n",
        "\n",
        "        self.grad_cam = GradCAM(model=model, target_layers=target_layers)\n",
        "\n",
        "        # Standard preprocessing transforms\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        print(f\"Fraud Detection Explainer initialized on {self.device}\")\n",
        "        print(f\"Target layers: {[type(layer).__name__ for layer in target_layers]}\")\n",
        "\n",
        "    def _find_target_layers(self):\n",
        "        \"\"\"Find the best target layer for EfficientNet Grad-CAM\"\"\"\n",
        "        # For EfficientNet, use the last convolutional layer\n",
        "        target_layers = []\n",
        "        for name, module in self.model.named_modules():\n",
        "            if isinstance(module, torch.nn.Conv2d):\n",
        "                target_layers = [module]\n",
        "\n",
        "        print(f\"Auto-detected target layer: {type(target_layers[0]).__name__}\")\n",
        "        return target_layers\n",
        "\n",
        "    def explain_prediction(self, image_tensor, true_label=None, target_class=None):\n",
        "        \"\"\"\n",
        "        Generate Grad-CAM explanation for a single image\n",
        "\n",
        "        Args:\n",
        "            image_tensor: Preprocessed image tensor\n",
        "            true_label: Ground truth label (for display)\n",
        "            target_class: Class to explain (None for predicted class)\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with prediction and explanation results\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "\n",
        "        # Get model prediction\n",
        "        with torch.no_grad():\n",
        "            output = self.model(image_tensor.unsqueeze(0).to(self.device))\n",
        "            probabilities = F.softmax(output, dim=1)\n",
        "            predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "            confidence = probabilities[0][predicted_class].item()\n",
        "\n",
        "        # Determine target for explanation\n",
        "        explain_class = target_class if target_class is not None else predicted_class\n",
        "        targets = [ClassifierOutputTarget(explain_class)]\n",
        "\n",
        "        # Generate Grad-CAM heatmap\n",
        "        input_tensor = image_tensor.unsqueeze(0).to(self.device)\n",
        "        grayscale_cam = self.grad_cam(input_tensor=input_tensor, targets=targets)\n",
        "        grayscale_cam = grayscale_cam[0, :]  # Remove batch dimension\n",
        "\n",
        "        # Prepare original image for visualization\n",
        "        original_image = self._tensor_to_image(image_tensor)\n",
        "\n",
        "        # Create CAM overlay\n",
        "        cam_visualization = show_cam_on_image(original_image, grayscale_cam, use_rgb=True)\n",
        "\n",
        "        # Prepare results\n",
        "        class_names = ['Authentic', 'Tampered']\n",
        "        result = {\n",
        "            'prediction': {\n",
        "                'class': class_names[predicted_class],\n",
        "                'class_id': predicted_class,\n",
        "                'confidence': confidence,\n",
        "                'probabilities': {\n",
        "                    'authentic': float(probabilities[0][0]),\n",
        "                    'tampered': float(probabilities[0][1])\n",
        "                }\n",
        "            },\n",
        "            'explanation': {\n",
        "                'target_class': class_names[explain_class],\n",
        "                'target_class_id': explain_class,\n",
        "                'heatmap_intensity': float(np.mean(grayscale_cam)),\n",
        "                'max_activation': float(np.max(grayscale_cam))\n",
        "            },\n",
        "            'visualization': {\n",
        "                'original_image': original_image,\n",
        "                'heatmap': grayscale_cam,\n",
        "                'cam_overlay': cam_visualization\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if true_label is not None:\n",
        "            result['ground_truth'] = {\n",
        "                'class': class_names[true_label],\n",
        "                'class_id': true_label,\n",
        "                'is_correct': predicted_class == true_label\n",
        "            }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def _tensor_to_image(self, tensor):\n",
        "        \"\"\"Convert normalized tensor to displayable image\"\"\"\n",
        "        # Denormalize\n",
        "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "\n",
        "        denorm_tensor = tensor * std + mean\n",
        "        denorm_tensor = torch.clamp(denorm_tensor, 0, 1)\n",
        "\n",
        "        # Convert to numpy\n",
        "        image_np = denorm_tensor.permute(1, 2, 0).numpy()\n",
        "        return image_np.astype(np.float32)\n",
        "\n",
        "def create_fraud_explainer(model_timestamp='20250603_145722'):\n",
        "    \"\"\"\n",
        "    Create fraud detection explainer from saved model\n",
        "\n",
        "    Args:\n",
        "        model_timestamp: Timestamp of saved model\n",
        "\n",
        "    Returns:\n",
        "        FraudDetectionExplainer instance\n",
        "    \"\"\"\n",
        "    print(\"Creating Grad-CAM explainer...\")\n",
        "\n",
        "    # Load the trained model\n",
        "    model, _ = load_best_model(model_timestamp)\n",
        "\n",
        "    # Create explainer\n",
        "    explainer = FraudDetectionExplainer(model)\n",
        "\n",
        "    return explainer\n",
        "\n",
        "def visualize_explanation(result, figsize=(15, 5), save_path=None):\n",
        "    \"\"\"\n",
        "    Create comprehensive visualization of Grad-CAM results\n",
        "\n",
        "    Args:\n",
        "        result: Result dictionary from explain_prediction\n",
        "        figsize: Figure size tuple\n",
        "        save_path: Optional save path\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
        "\n",
        "    # Original image\n",
        "    axes[0].imshow(result['visualization']['original_image'])\n",
        "    axes[0].set_title('Original Image', fontsize=12)\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Heatmap\n",
        "    im = axes[1].imshow(result['visualization']['heatmap'], cmap='jet')\n",
        "    axes[1].set_title(f\"Grad-CAM Heatmap\\n(Intensity: {result['explanation']['heatmap_intensity']:.3f})\",\n",
        "                      fontsize=12)\n",
        "    axes[1].axis('off')\n",
        "    plt.colorbar(im, ax=axes[1], fraction=0.046)\n",
        "\n",
        "    # Overlay visualization\n",
        "    axes[2].imshow(result['visualization']['cam_overlay'])\n",
        "\n",
        "    # Create detailed title for overlay\n",
        "    pred = result['prediction']\n",
        "    exp = result['explanation']\n",
        "\n",
        "    title = f\"Prediction: {pred['class']} ({pred['confidence']:.3f})\\n\"\n",
        "    title += f\"Explaining: {exp['target_class']}\"\n",
        "\n",
        "    if 'ground_truth' in result:\n",
        "        gt = result['ground_truth']\n",
        "        correctness = \"✓\" if gt['is_correct'] else \"✗\"\n",
        "        title += f\"\\nGround Truth: {gt['class']} {correctness}\"\n",
        "\n",
        "    axes[2].set_title(title, fontsize=12)\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Visualization saved to: {save_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def analyze_tampering_focus(result):\n",
        "    \"\"\"\n",
        "    Analyze what regions the model focuses on for tampering detection\n",
        "\n",
        "    Args:\n",
        "        result: Result dictionary from explain_prediction\n",
        "    \"\"\"\n",
        "    heatmap = result['visualization']['heatmap']\n",
        "    pred = result['prediction']\n",
        "\n",
        "    # Calculate focus statistics\n",
        "    high_activation_threshold = 0.7\n",
        "    medium_activation_threshold = 0.4\n",
        "\n",
        "    high_focus_ratio = np.sum(heatmap > high_activation_threshold) / heatmap.size\n",
        "    medium_focus_ratio = np.sum(heatmap > medium_activation_threshold) / heatmap.size\n",
        "\n",
        "    print(f\"\\nTampering Detection Focus Analysis:\")\n",
        "    print(f\"Predicted Class: {pred['class']} (confidence: {pred['confidence']:.3f})\")\n",
        "    print(f\"High activation regions (>{high_activation_threshold}): {high_focus_ratio:.2%}\")\n",
        "    print(f\"Medium activation regions (>{medium_activation_threshold}): {medium_focus_ratio:.2%}\")\n",
        "    print(f\"Average activation intensity: {result['explanation']['heatmap_intensity']:.3f}\")\n",
        "    print(f\"Maximum activation intensity: {result['explanation']['max_activation']:.3f}\")\n",
        "\n",
        "    # Provide interpretation guidance\n",
        "    if pred['class'] == 'Tampered':\n",
        "        if high_focus_ratio > 0.1:\n",
        "            print(\"Interpretation: Model detected strong tampering artifacts in multiple regions\")\n",
        "        elif medium_focus_ratio > 0.2:\n",
        "            print(\"Interpretation: Model detected moderate tampering artifacts across image\")\n",
        "        else:\n",
        "            print(\"Interpretation: Model detected subtle tampering artifacts\")\n",
        "    else:\n",
        "        if high_focus_ratio < 0.05:\n",
        "            print(\"Interpretation: Model found consistent authentic patterns throughout image\")\n",
        "        else:\n",
        "            print(\"Interpretation: Model detected some suspicious regions but overall classified as authentic\")"
      ],
      "metadata": {
        "id": "PDJBnYdTdPgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_gradcam_samples(explainer, test_loader, num_samples=6):\n",
        "    \"\"\"\n",
        "    Test Grad-CAM on sample images from test set\n",
        "\n",
        "    Args:\n",
        "        explainer: FraudDetectionExplainer instance\n",
        "        test_loader: Test data loader\n",
        "        num_samples: Number of samples to analyze\n",
        "    \"\"\"\n",
        "    print(\"Testing Grad-CAM on sample images from test set...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Get sample batch\n",
        "    images, labels = next(iter(test_loader))\n",
        "\n",
        "    for i in range(min(num_samples, len(images))):\n",
        "        print(f\"\\nAnalyzing Sample {i+1}/{num_samples}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Get explanation\n",
        "        result = explainer.explain_prediction(images[i], true_label=labels[i].item())\n",
        "\n",
        "        # Visualize\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        save_path = f'/content/drive/MyDrive/fraud_detection/outputs/gradcam_sample_{i+1}_{timestamp}.png'\n",
        "        visualize_explanation(result, save_path=save_path)\n",
        "\n",
        "        # Analyze focus patterns\n",
        "        analyze_tampering_focus(result)\n",
        "\n",
        "def test_gradcam_interesting_cases(explainer, test_loader):\n",
        "    \"\"\"\n",
        "    Test Grad-CAM on interesting cases (high/low confidence, correct/incorrect)\n",
        "\n",
        "    Args:\n",
        "        explainer: FraudDetectionExplainer instance\n",
        "        test_loader: Test data loader\n",
        "    \"\"\"\n",
        "    print(\"\\nFinding interesting cases for detailed Grad-CAM analysis...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    explainer.model.eval()\n",
        "\n",
        "    # Collect interesting cases\n",
        "    cases = {\n",
        "        'high_conf_correct': [],\n",
        "        'high_conf_incorrect': [],\n",
        "        'low_conf_correct': [],\n",
        "        'tampered_detected': [],\n",
        "        'tampered_missed': []\n",
        "    }\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_images, batch_labels in test_loader:\n",
        "            batch_images = batch_images.to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "\n",
        "            outputs = explainer.model(batch_images)\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            for i in range(len(batch_images)):\n",
        "                confidence = probs[i].max().item()\n",
        "                true_label = batch_labels[i].item()\n",
        "                pred_label = predicted[i].item()\n",
        "                is_correct = pred_label == true_label\n",
        "\n",
        "                case_info = {\n",
        "                    'image': batch_images[i].cpu(),\n",
        "                    'true_label': true_label,\n",
        "                    'predicted': pred_label,\n",
        "                    'confidence': confidence,\n",
        "                    'is_correct': is_correct\n",
        "                }\n",
        "\n",
        "                # Categorize cases\n",
        "                if confidence > 0.9 and is_correct and len(cases['high_conf_correct']) < 2:\n",
        "                    cases['high_conf_correct'].append(case_info)\n",
        "                elif confidence > 0.9 and not is_correct and len(cases['high_conf_incorrect']) < 2:\n",
        "                    cases['high_conf_incorrect'].append(case_info)\n",
        "                elif confidence < 0.7 and is_correct and len(cases['low_conf_correct']) < 2:\n",
        "                    cases['low_conf_correct'].append(case_info)\n",
        "                elif true_label == 1 and pred_label == 1 and len(cases['tampered_detected']) < 2:\n",
        "                    cases['tampered_detected'].append(case_info)\n",
        "                elif true_label == 1 and pred_label == 0 and len(cases['tampered_missed']) < 2:\n",
        "                    cases['tampered_missed'].append(case_info)\n",
        "\n",
        "    # Analyze each category\n",
        "    class_names = ['Authentic', 'Tampered']\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    for case_type, case_list in cases.items():\n",
        "        if case_list:\n",
        "            print(f\"\\n{case_type.replace('_', ' ').title()} Cases:\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            for j, case in enumerate(case_list):\n",
        "                print(f\"\\nCase {j+1}: True={class_names[case['true_label']]}, \"\n",
        "                      f\"Pred={class_names[case['predicted']]} (conf: {case['confidence']:.3f})\")\n",
        "\n",
        "                # Generate explanation\n",
        "                result = explainer.explain_prediction(\n",
        "                    case['image'],\n",
        "                    true_label=case['true_label']\n",
        "                )\n",
        "\n",
        "                # Save visualization\n",
        "                save_path = f'/content/drive/MyDrive/fraud_detection/outputs/gradcam_{case_type}_{j+1}_{timestamp}.png'\n",
        "                visualize_explanation(result, save_path=save_path)\n",
        "\n",
        "                # Analyze focus\n",
        "                analyze_tampering_focus(result)\n",
        "\n",
        "# Create explainer instance\n",
        "print(\"Initializing Grad-CAM explainer for fraud detection model...\")\n",
        "explainer = create_fraud_explainer('20250603_145722')"
      ],
      "metadata": {
        "id": "l_3Z0abbdtR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grad-CAM Results"
      ],
      "metadata": {
        "id": "dtMjqRIEdpoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on random sample images\n",
        "test_gradcam_samples(explainer, test_loader, num_samples=6)"
      ],
      "metadata": {
        "id": "zWN0i3RGeaZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grad-CAM Analysis"
      ],
      "metadata": {
        "id": "OFVYkXawgbhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test on specific interesting cases\n",
        "test_gradcam_interesting_cases(explainer, test_loader)"
      ],
      "metadata": {
        "id": "KM00xpzoe97W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_class_explanations(explainer, image_tensor, true_label=None):\n",
        "    \"\"\"\n",
        "    Compare Grad-CAM explanations for both classes on the same image\n",
        "\n",
        "    Args:\n",
        "        explainer: FraudDetectionExplainer instance\n",
        "        image_tensor: Input image tensor\n",
        "        true_label: Ground truth label\n",
        "    \"\"\"\n",
        "    print(\"\\nComparing explanations for both classes on the same image...\")\n",
        "\n",
        "    # Get explanations for both classes\n",
        "    authentic_result = explainer.explain_prediction(image_tensor, true_label, target_class=0)\n",
        "    tampered_result = explainer.explain_prediction(image_tensor, true_label, target_class=1)\n",
        "\n",
        "    # Create comparison visualization\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "    # Original image (shown twice for reference)\n",
        "    for row in range(2):\n",
        "        axes[row, 0].imshow(authentic_result['visualization']['original_image'])\n",
        "        axes[row, 0].set_title('Original Image')\n",
        "        axes[row, 0].axis('off')\n",
        "\n",
        "    # Authentic explanation\n",
        "    axes[0, 1].imshow(authentic_result['visualization']['heatmap'], cmap='jet')\n",
        "    axes[0, 1].set_title(f\"Authentic Class Explanation\\n(Intensity: {authentic_result['explanation']['heatmap_intensity']:.3f})\")\n",
        "    axes[0, 1].axis('off')\n",
        "\n",
        "    axes[0, 2].imshow(authentic_result['visualization']['cam_overlay'])\n",
        "    auth_conf = authentic_result['prediction']['probabilities']['authentic']\n",
        "    axes[0, 2].set_title(f\"Authentic Overlay\\n(Prob: {auth_conf:.3f})\")\n",
        "    axes[0, 2].axis('off')\n",
        "\n",
        "    # Tampered explanation\n",
        "    axes[1, 1].imshow(tampered_result['visualization']['heatmap'], cmap='jet')\n",
        "    axes[1, 1].set_title(f\"Tampered Class Explanation\\n(Intensity: {tampered_result['explanation']['heatmap_intensity']:.3f})\")\n",
        "    axes[1, 1].axis('off')\n",
        "\n",
        "    axes[1, 2].imshow(tampered_result['visualization']['cam_overlay'])\n",
        "    tamp_conf = tampered_result['prediction']['probabilities']['tampered']\n",
        "    axes[1, 2].set_title(f\"Tampered Overlay\\n(Prob: {tamp_conf:.3f})\")\n",
        "    axes[1, 2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save comparison\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    save_path = f'/content/drive/MyDrive/fraud_detection/outputs/gradcam_comparison_{timestamp}.png'\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Class comparison saved to: {save_path}\")\n",
        "\n",
        "    # Analyze differences\n",
        "    auth_intensity = authentic_result['explanation']['heatmap_intensity']\n",
        "    tamp_intensity = tampered_result['explanation']['heatmap_intensity']\n",
        "\n",
        "    print(f\"\\nClass Explanation Comparison:\")\n",
        "    print(f\"Authentic explanation intensity: {auth_intensity:.3f}\")\n",
        "    print(f\"Tampered explanation intensity: {tamp_intensity:.3f}\")\n",
        "    print(f\"Intensity difference: {abs(tamp_intensity - auth_intensity):.3f}\")\n",
        "\n",
        "    if tamp_intensity > auth_intensity:\n",
        "        print(\"Model shows stronger activation patterns when explaining tampering\")\n",
        "    else:\n",
        "        print(\"Model shows stronger activation patterns when explaining authenticity\")\n",
        "\n",
        "# Test comparison on an interesting image\n",
        "print(\"Running comparative class explanation analysis...\")\n",
        "images, labels = next(iter(test_loader))\n",
        "compare_class_explanations(explainer, images[0], labels[0].item())\n",
        "\n",
        "print(\"\\nGrad-CAM analysis complete!\")\n",
        "print(\"All visualizations saved to /content/drive/MyDrive/fraud_detection/outputs/\")"
      ],
      "metadata": {
        "id": "8vKpIBohfbex"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}